{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get single author's texts\n",
    "with open(\"../txt/marx_engels/marx_engels_total.txt\") as f:\n",
    "    me_total = f.read()\n",
    "with open(\"../txt/trotzki/trotzki_total.txt\") as f:\n",
    "    trotzki_total = f.read()\n",
    "with open(\"../txt/stalin/stalin_total.txt\") as f:\n",
    "    stalin_total = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get whole corpus\n",
    "with open(\"../txt/all.txt\") as f:\n",
    "    all_total = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(text):\n",
    "    sents = sent_tokenize(text)\n",
    "    words = [word_tokenize(sent) for sent in sents]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare single author's texts\n",
    "me_prepared = prepare(me_total)\n",
    "trotzki_prepared = prepare(trotzki_total)\n",
    "stalin_prepared = prepare(stalin_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare whole corpus\n",
    "all_prepared = prepare(all_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get reference corpus\n",
    "with open(\"german-amazon-reviews.txt\", encoding=\"iso-8859-15\") as f:\n",
    "    amazon = f.read()\n",
    "amazon_prepared = prepare(amazon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model for whole corpus\n",
    "model_all = Word2Vec(all_prepared, size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Perrier', 0.6235110759735107),\n",
       " ('Stuart', 0.6121819019317627),\n",
       " ('Staatsprokurator', 0.6116944551467896),\n",
       " ('gläubige', 0.608957052230835),\n",
       " ('Krummacher', 0.6083165407180786),\n",
       " ('Thompson', 0.6060768365859985),\n",
       " ('Madame', 0.6056742072105408),\n",
       " ('Fould', 0.6023613810539246),\n",
       " ('Clément', 0.6016688942909241),\n",
       " ('Tochter', 0.597574770450592),\n",
       " ('Advokat', 0.5965981483459473),\n",
       " ('Weerth', 0.5941691398620605),\n",
       " ('Gagern', 0.5936335921287537),\n",
       " ('Aristokrat', 0.5928776264190674),\n",
       " ('Schimmelpfennig', 0.5920757055282593),\n",
       " ('Demokrat', 0.5877822041511536),\n",
       " ('Student', 0.5867450833320618),\n",
       " ('Cabet', 0.5863481163978577),\n",
       " ('Sasonow', 0.5862720608711243),\n",
       " ('Haller', 0.5827111005783081),\n",
       " ('älteste', 0.5825262069702148),\n",
       " ('Howell', 0.5817673206329346),\n",
       " ('stoische', 0.5815796256065369),\n",
       " ('Inspektor', 0.5808447599411011),\n",
       " ('Paléologue', 0.5802479386329651),\n",
       " ('ehrwürdige', 0.58016037940979),\n",
       " ('Thomas', 0.57985919713974),\n",
       " ('Odilon', 0.5797971487045288),\n",
       " ('Dudley', 0.5792602300643921),\n",
       " ('Lincoln', 0.5789412260055542),\n",
       " ('Yorke', 0.5784074664115906),\n",
       " ('Maria', 0.5771102905273438),\n",
       " ('Pfaffe', 0.5769452452659607),\n",
       " ('Jean', 0.5765843391418457),\n",
       " ('Blenker', 0.5765454173088074),\n",
       " ('Netschajew', 0.5758488774299622),\n",
       " ('Jungfrau', 0.57529616355896),\n",
       " ('Reichenbach', 0.5752747058868408),\n",
       " ('Friedensgesellschaft', 0.5750494003295898),\n",
       " ('Humphrey', 0.5750480890274048),\n",
       " ('Cambon', 0.5746475458145142),\n",
       " ('Shaftesbury', 0.5739035606384277),\n",
       " ('Sidney', 0.5738122463226318),\n",
       " ('Urquhart', 0.5737548470497131),\n",
       " ('Konservativer', 0.572451114654541),\n",
       " ('Samuel', 0.5723336935043335),\n",
       " ('Lump', 0.5720323324203491),\n",
       " ('Richardson', 0.570704460144043),\n",
       " ('Parteigenosse', 0.5700960159301758),\n",
       " ('pikante', 0.5700027942657471),\n",
       " ('Journalist', 0.5692251920700073),\n",
       " ('ehemaliger', 0.568475604057312),\n",
       " ('Comte', 0.5684270262718201),\n",
       " ('Gustav', 0.5682985782623291),\n",
       " ('Adolf', 0.5676270127296448),\n",
       " ('Russki', 0.567332923412323),\n",
       " ('Senior', 0.5667616128921509),\n",
       " ('Ernest', 0.5664025545120239),\n",
       " ('Harris', 0.565255880355835),\n",
       " ('Opportunist', 0.5651882886886597),\n",
       " ('Kommandant', 0.56488037109375),\n",
       " ('Brown', 0.5642052888870239),\n",
       " ('Zimmermann', 0.5641510486602783),\n",
       " ('Anarchist', 0.5639994144439697),\n",
       " ('Reuter', 0.563558042049408),\n",
       " ('Hall', 0.5633563995361328),\n",
       " ('Loyd', 0.5628736019134521),\n",
       " ('Schatzmeister', 0.5628362894058228),\n",
       " ('angesehener', 0.5627653002738953),\n",
       " ('Fox', 0.5626565217971802),\n",
       " ('Parlamentsmitglied', 0.561892032623291),\n",
       " ('wackere', 0.5618065595626831),\n",
       " ('Edgar', 0.5617548227310181),\n",
       " ('Pastor', 0.5614580512046814),\n",
       " ('Publizist', 0.561456024646759),\n",
       " ('gottesfürchtige', 0.5608157515525818),\n",
       " ('Simon', 0.5602602362632751),\n",
       " ('Locke', 0.5602061748504639),\n",
       " ('Zetkin', 0.5596626996994019),\n",
       " ('gelehrte', 0.5595988631248474),\n",
       " ('Drigalski', 0.5583869218826294),\n",
       " ('Burnes', 0.5583515763282776),\n",
       " ('Alexandrowna', 0.5581654906272888),\n",
       " ('Gräfin', 0.5577081441879272),\n",
       " ('Bublikow', 0.5574743747711182),\n",
       " ('Techow', 0.5573744773864746),\n",
       " ('Christ', 0.5571892261505127),\n",
       " ('Taylor', 0.5569892525672913),\n",
       " ('Propagandist', 0.5569868087768555),\n",
       " ('Hugo', 0.5569801330566406),\n",
       " ('Wise', 0.5569781064987183),\n",
       " ('Garnier-Pagès', 0.5567776560783386),\n",
       " ('Schaible', 0.5566117763519287),\n",
       " ('Panmure', 0.5564060807228088),\n",
       " ('Gambuzzi', 0.5562161207199097),\n",
       " ('More', 0.5560238361358643),\n",
       " ('Gorki', 0.5559460520744324),\n",
       " ('Admiralität', 0.5559095144271851),\n",
       " ('Dame', 0.5556259155273438),\n",
       " ('Abgeordneter', 0.5555663108825684)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get analogies\n",
    "model_all.wv.most_similar(positive=[\"Junge\", \"Frau\"], negative=[\"Mann\"], topn=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "me\n",
      "trotzki\n",
      "stalin\n",
      "amazon\n"
     ]
    }
   ],
   "source": [
    "# build models for single author's texts\n",
    "print(\"me\")\n",
    "model_me = Word2Vec(me_prepared, size=300)\n",
    "print(\"trotzki\")\n",
    "model_trotzki = Word2Vec(trotzki_prepared, size=300)\n",
    "print(\"stalin\")\n",
    "model_stalin = Word2Vec(stalin_prepared, size=300)\n",
    "print(\"amazon\")\n",
    "model_amazon = Word2Vec(amazon_prepared, size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Flotte', 0.818668007850647), ('Truppen', 0.8157972097396851), ('Kavallerie', 0.7579588890075684), ('Artillerie', 0.7291944622993469), ('Position', 0.7245581150054932), ('Streitkräfte', 0.7153795957565308), ('Festung', 0.714713454246521), ('Garnison', 0.7123770117759705), ('Infanterie', 0.7063800096511841), ('Schlacht', 0.7007136940956116)]\n",
      "[('Bürokratie', 0.9351111650466919), ('Sozialdemokratie', 0.9092366099357605), ('Bourgeoisie', 0.9002584218978882), ('Arbeiterklasse', 0.898350715637207), ('Intelligenz', 0.8885919451713562), ('Garnison', 0.8768906593322754), ('Bauernschaft', 0.8748764395713806), ('UdSSR', 0.8641899824142456), ('Bewegung', 0.8611583709716797), ('Wirtschaft', 0.8566991090774536)]\n",
      "[('Heimat', 0.7084632515907288), ('Flotte', 0.6961424946784973), ('Truppen', 0.6792908906936646), ('Aufbauarbeit', 0.6564610600471497), ('Armeen', 0.6428441405296326), ('Front', 0.6264467239379883), ('Gewerkschaftsinternationale', 0.6186168193817139), ('Funktionäre', 0.6159325242042542), ('Parteiorganisationen', 0.6135824918746948), ('Kraft', 0.6133130192756653)]\n",
      "[('Rasse', 0.7073506116867065), ('Regierung', 0.7038128972053528), ('Kolonie', 0.6921778321266174), ('BrÃŒcke', 0.6740583777427673), ('Mauer', 0.6717073917388916), ('Gesellschaft', 0.6646957993507385), ('Bedrohung', 0.655580997467041), ('Gemeinschaft', 0.6537054777145386), ('Mission', 0.6498859524726868), ('KÃ¶nigin', 0.6478523015975952)]\n"
     ]
    }
   ],
   "source": [
    "# get lists of similar words for single author's texts\n",
    "word = \"Armee\"\n",
    "n = 10\n",
    "\n",
    "sim_me = model_me.wv.similar_by_vector(word, topn=n)\n",
    "print(sim_me)\n",
    "sim_me = {elem[0]:i+1 for i, elem in enumerate(sim_me)}\n",
    "\n",
    "sim_t = model_trotzki.wv.similar_by_vector(word, topn=n)\n",
    "print(sim_t)\n",
    "sim_t = {elem[0]:i+1 for i, elem in enumerate(sim_t)}\n",
    "\n",
    "sim_s = model_stalin.wv.similar_by_vector(word, topn=n)\n",
    "print(sim_s)\n",
    "sim_s = {elem[0]:i+1 for i, elem in enumerate(sim_s)}\n",
    "\n",
    "sim_a = model_amazon.wv.similar_by_vector(word, topn=n)\n",
    "print(sim_a)\n",
    "sim_a = {elem[0]:i+1 for i, elem in enumerate(sim_a)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_lists(l1, l2):\n",
    "    d1 = {elem[0]: i+1 for i, elem in enumerate(l1)}\n",
    "    d2 = {elem[0]: i+1 for i, elem in enumerate(l2)}\n",
    "    s1 = set(d1)\n",
    "    s2 = set(d2)\n",
    "\n",
    "    res = 0\n",
    "    for elem in s1.intersection(s2):\n",
    "        res += (len(l1) - abs(d1[elem] - d2[elem])) / len(l1)**2\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trotzki: 0.26\n",
      "Stalin:  0.44999999999999996\n",
      "T-S   :  0.18\n",
      "Amazon:  0.13\n"
     ]
    }
   ],
   "source": [
    "# print similarities between single authors\n",
    "print(\"Trotzki:\", compare_lists(sim_me, sim_t))\n",
    "print(\"Stalin: \", compare_lists(sim_me, sim_s))\n",
    "print(\"T-S   : \", compare_lists(sim_s, sim_t))\n",
    "print(\"Amazon: \", compare_lists(sim_me, sim_a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
